# Adaptive Cryptocurrency Trading Bot

This repository contains a complete, self-learning cryptocurrency trading bot that uses machine learning to adapt to market conditions and optimize trading strategies automatically.

## Architecture Overview

The bot consists of three main components:

1. **Elixir Backend**: Handles trading logic, strategy execution, and API integration
2. **Python ML Service**: Provides machine learning capabilities including market regime detection and reinforcement learning
3. **Svelte Frontend**: Offers an intuitive dashboard for monitoring and control

## Core Features

- **Market Regime Detection**: Automatically identifies trending, sideways, or volatile markets
- **Adaptive Strategy Selection**: Chooses optimal strategies based on current market conditions
- **Multi-Exchange Support**: Works with Binance, Coinbase Pro, Kraken, and other exchanges
- **Advanced Correlation Analysis**: Tracks correlations between main cryptocurrencies and smaller altcoins
- **Risk Management**: Built-in safeguards to protect your portfolio
- **Performance Monitoring**: Comprehensive dashboard for tracking results

## Directory Structure

```
adaptive-crypto-bot/
â”œâ”€â”€ backend/                      # Elixir Backend
â”‚   â”œâ”€â”€ lib/                      # Main code
â”‚   â”‚   â”œâ”€â”€ crypto_bot/           # Core modules
â”‚   â”‚   â”‚   â”œâ”€â”€ adaptive_router.ex      # Dynamic strategy router
â”‚   â”‚   â”‚   â”œâ”€â”€ market_analyzer.ex      # Market analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ strategies/             # Trading strategies
â”‚   â”‚   â”‚   â”œâ”€â”€ strategy_optimizer.ex   # Parameter tuning
â”‚   â”‚   â”‚   â”œâ”€â”€ adaptation_engine.ex    # Self-learning system
â”‚   â”‚   â”‚   â””â”€â”€ strategy_validator.ex   # Safety checks
â”‚   â”‚   â””â”€â”€ crypto_bot_web/       # Web interface and API
â”‚   â”œâ”€â”€ config/                # Configuration files
â”‚   â””â”€â”€ mix.exs                # Elixir dependencies
â”‚
â”œâ”€â”€ ml_service/               # Python ML Service
â”‚   â”œâ”€â”€ models/               # ML models
â”‚   â”‚   â”œâ”€â”€ regime_detector.py      # Market regime detection
â”‚   â”‚   â”œâ”€â”€ strategy_rl_agent.py    # Reinforcement learning
â”‚   â”‚   â”œâ”€â”€ market_embedder.py      # Market embedding
â”‚   â”‚   â””â”€â”€ strategy_ensemble.py    # Multi-model ensemble
â”‚   â”œâ”€â”€ app.py                # Flask API
â”‚   â””â”€â”€ requirements.txt      # Python dependencies
â”‚
â”œâ”€â”€ frontend/                # Svelte Frontend
â”‚   â”œâ”€â”€ src/                 # Source code
â”‚   â”‚   â”œâ”€â”€ components/           # UI components
â”‚   â”‚   â”œâ”€â”€ stores/               # State management
â”‚   â”‚   â”œâ”€â”€ routes/               # Pages
â”‚   â”‚   â””â”€â”€ App.svelte            # Main application
â”‚   â””â”€â”€ package.json         # JS dependencies
â”‚
â”œâ”€â”€ docker/                  # Docker configuration
â”‚   â”œâ”€â”€ Dockerfile.backend    # Elixir container
â”‚   â”œâ”€â”€ Dockerfile.ml         # Python container
â”‚   â”œâ”€â”€ Dockerfile.frontend   # Frontend container
â”‚   â””â”€â”€ docker-compose.yml    # Orchestration
â”‚
â””â”€â”€ scripts/                 # Helper scripts
    â”œâ”€â”€ setup.sh              # Setup
    â””â”€â”€ start.sh              # Start all services
```

## Setup Instructions

### Prerequisites

- Docker and Docker Compose
- A server with at least 4 CPU cores, 8GB RAM, and 40GB storage
- API keys from supported cryptocurrency exchanges
- (Optional) NVIDIA GPU for accelerated ML training

### Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/adaptive-crypto-bot.git
   cd adaptive-crypto-bot
   ```

2. Configure environment variables:
   ```bash
   cp .env.example .env
   # Edit .env with your API keys and settings
   ```

3. Start the bot:
   ```bash
   ./scripts/start.sh
   ```

4. Access the dashboard:
   ```
   http://localhost:3000
   ```

## Key Components Implementation

### 1. Elixir Backend: Adaptive Strategy Router

```elixir
# backend/lib/crypto_bot/strategy/adaptive_router.ex
defmodule CryptoBot.Strategy.AdaptiveRouter do
  use GenServer

  @strategies %{
    trend_following: {CryptoBot.Strategies.EMATrend, %{short: 9, long: 21}},
    mean_reversion: {CryptoBot.Strategies.Grid, %{width: 2.0, levels: 10}},
    arbitrage: {CryptoBot.Strategies.Arbitrage, %{}},
    market_making: {CryptoBot.Strategies.MarketMaker, %{spread: 0.5}}
  }

  def start_link(_) do
    GenServer.start_link(__MODULE__, [], name: __MODULE__)
  end

  def get_strategy(symbol) do
    GenServer.call(__MODULE__, {:get_strategy, symbol})
  end

  def handle_call({:get_strategy, symbol}, _from, state) do
    # Get current market regime and volatility
    %{regime: regime, volatility: vol} = CryptoBot.MarketAnalyzer.analyze(symbol)
    
    # Select optimal strategy based on market conditions
    strategy = 
      case {regime, vol} do
        {:trending, v} when v > 0.05 -> @strategies.trend_following
        {:sideways, _} -> @strategies.mean_reversion
        {:volatile, _} -> @strategies.market_making
        _ -> @strategies.trend_following
      end
    
    # Optimize parameters for current market
    {module, base_params} = strategy
    optimized_params = optimize_parameters(module, base_params, symbol)
    
    {:reply, {:ok, module, optimized_params}, state}
  end

  defp optimize_parameters(module, base_params, symbol) do
    # Get historical data for parameter optimization
    historical_data = CryptoBot.MarketData.history(symbol, "1d", 30)
    
    # Different optimization logic for each strategy type
    case module do
      CryptoBot.Strategies.EMATrend ->
        # Optimize EMA periods
        Map.merge(base_params, %{
          short: optimize_ema_period(historical_data, :short),
          long: optimize_ema_period(historical_data, :long)
        })
      
      CryptoBot.Strategies.Grid ->
        # Optimize grid width and levels
        Map.merge(base_params, %{
          width: optimize_grid_width(historical_data),
          levels: optimize_grid_levels(historical_data)
        })
      
      _ -> base_params
    end
  end

  # Strategy-specific optimization functions
  defp optimize_ema_period(data, type) do
    # Simple optimization logic (would be more complex in production)
    vol = calculate_volatility(data)
    
    case {type, vol} do
      {:short, v} when v > 0.03 -> 7
      {:short, _} -> 9
      {:long, v} when v > 0.03 -> 18
      {:long, _} -> 21
    end
  end
  
  defp optimize_grid_width(data) do
    vol = calculate_volatility(data)
    cond do
      vol > 0.04 -> 3.0
      vol > 0.02 -> 2.0
      true -> 1.5
    end
  end
  
  defp optimize_grid_levels(data) do
    vol = calculate_volatility(data)
    cond do
      vol > 0.04 -> 6
      vol > 0.02 -> 10
      true -> 12
    end
  end
  
  defp calculate_volatility(price_data) do
    # Calculate standard deviation of returns
    prices = Enum.map(price_data, & &1.close)
    returns = calculate_returns(prices)
    std_dev(returns)
  end
  
  defp calculate_returns(prices) do
    prices
    |> Enum.chunk_every(2, 1, :discard)
    |> Enum.map(fn [prev, current] -> (current - prev) / prev end)
  end
  
  defp std_dev(list) do
    mean = Enum.sum(list) / Enum.count(list)
    
    list
    |> Enum.map(fn x -> :math.pow(x - mean, 2) end)
    |> Enum.sum()
    |> Kernel./(Enum.count(list))
    |> :math.sqrt()
  end
end
```

### 2. Python ML Service: Market Regime Detection

```python
# ml_service/models/regime_detector.py
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from hmmlearn.hmm import GaussianHMM

class RegimeDetectionService:
    def __init__(self, model_dir="models/saved"):
        self.model_dir = model_dir
        self.detector = MarketRegimeDetector()
        self.is_trained = False
        self.load_models()
    
    def load_models(self):
        try:
            self.detector.load_models(f"{self.model_dir}/regime_detector")
            self.is_trained = True
        except:
            # Models will be trained on first use
            pass
    
    def detect_regime(self, symbol, market_data):
        """Detect market regime for a given symbol."""
        # Extract relevant features
        if not self.is_trained:
            # Train on historical data
            self._train_on_history(symbol)
        
        # Prepare data
        features = self._extract_features(market_data)
        
        # Detect regime
        regime = self.detector.predict(features)
        
        # Calculate confidence
        confidence = self.detector.regime_confidence(features)
        
        return {
            "symbol": symbol,
            "regime": regime,
            "confidence": confidence,
            "timestamp": pd.Timestamp.now().isoformat()
        }
    
    def _train_on_history(self, symbol):
        """Train regime detector on historical data."""
        # In a real system, fetch historical data
        historical_data = self._fetch_historical_data(symbol)
        
        # Train detector
        self.detector.train(historical_data)
        self.is_trained = True
        
        # Save model
        self.detector.save_models(f"{self.model_dir}/regime_detector_{symbol}")
    
    def _extract_features(self, market_data):
        """Extract features for regime detection."""
        try:
            # Extract OHLCV data
            if 'close' in market_data:
                # OHLCV format
                returns = np.diff(np.log(market_data['close']))
                volatility = np.std(returns) if len(returns) > 1 else 0
                volume_change = np.diff(np.log(market_data['volume'])) if 'volume' in market_data else np.zeros(len(returns))
                
                features = np.column_stack([returns, volatility * np.ones_like(returns), volume_change])
                return features
            else:
                # Simple dict format
                volatility = market_data.get('volatility', 0.01)
                volume = market_data.get('volume', 1000)
                return np.array([[volatility, volume]])
        except Exception as e:
            # Fallback to default features
            return np.array([[0.01, 1000]])
    
    def _fetch_historical_data(self, symbol):
        """Fetch historical data for training."""
        # In a real system, implement exchange API calls
        # For demo, return dummy data
        return {
            'close': np.random.lognormal(0, 0.01, 1000) * 1000,
            'volume': np.random.lognormal(0, 0.1, 1000) * 10000
        }


class MarketRegimeDetector:
    def __init__(self, n_regimes=3):
        """Initialize market regime detector."""
        self.n_regimes = n_regimes
        self.model = GaussianHMM(
            n_components=n_regimes,
            covariance_type="diag",
            n_iter=1000,
            random_state=42
        )
        self.scaler = StandardScaler()
        self.regime_labels = {
            0: "trending",
            1: "sideways",
            2: "volatile"
        }
        self.is_trained = False
    
    def train(self, data, volumes=None):
        """Train the detector on price and volume data."""
        # Process data
        if isinstance(data, dict):
            prices = data['close']
            volumes = data.get('volume', None)
        else:
            prices = data
        
        # Calculate features
        returns = np.diff(np.log(prices))
        if len(returns) < 10:
            return False
        
        # Add volume features if available
        if volumes is not None:
            volume_changes = np.diff(np.log(volumes[:len(returns)+1]))
            features = np.column_stack([returns, volume_changes])
        else:
            # Just use returns and volatility
            volatility = np.std(returns) * np.ones_like(returns)
            features = np.column_stack([returns, volatility])
        
        # Scale features
        self.scaler.fit(features)
        scaled_features = self.scaler.transform(features)
        
        # Train HMM model
        self.model.fit(scaled_features)
        self.is_trained = True
        
        return True
    
    def predict(self, features):
        """Predict the current market regime."""
        if not self.is_trained:
            return "unknown"
        
        # Handle different input formats
        if len(features.shape) == 1:
            features = features.reshape(1, -1)
        
        # Scale features
        try:
            scaled_features = self.scaler.transform(features)
        except:
            # If shape mismatch, try to adapt
            if features.shape[1] != self.scaler.n_features_in_:
                # Pad or truncate features
                padded = np.zeros((features.shape[0], self.scaler.n_features_in_))
                padded[:, :min(features.shape[1], self.scaler.n_features_in_)] = features[:, :min(features.shape[1], self.scaler.n_features_in_)]
                scaled_features = self.scaler.transform(padded)
            else:
                raise
        
        # Get the most likely regime
        regime_idx = self.model.predict(scaled_features)[-1]
        
        return self.regime_labels.get(regime_idx, "unknown")
    
    def regime_confidence(self, features):
        """Calculate confidence in the regime prediction."""
        if not self.is_trained:
            return 0.5
        
        # Scale features
        if len(features.shape) == 1:
            features = features.reshape(1, -1)
        
        try:
            scaled_features = self.scaler.transform(features)
        except:
            # Handle mismatched features
            if features.shape[1] != self.scaler.n_features_in_:
                padded = np.zeros((features.shape[0], self.scaler.n_features_in_))
                padded[:, :min(features.shape[1], self.scaler.n_features_in_)] = features[:, :min(features.shape[1], self.scaler.n_features_in_)]
                scaled_features = self.scaler.transform(padded)
            else:
                return 0.5
        
        # Use model scores as confidence
        log_probs = self.model.score_samples(scaled_features)
        # Normalize to 0-1 range
        confidence = np.exp(log_probs[-1] - np.min(log_probs)) / np.exp(np.max(log_probs) - np.min(log_probs))
        
        return float(confidence)
    
    def save_models(self, path):
        """Save models to disk."""
        import joblib
        joblib.dump({'model': self.model, 'scaler': self.scaler}, f"{path}.joblib")
    
    def load_models(self, path):
        """Load models from disk."""
        import joblib
        import os
        
        if not os.path.exists(f"{path}.joblib"):
            raise FileNotFoundError(f"Model file not found: {path}.joblib")
        
        saved = joblib.load(f"{path}.joblib")
        self.model = saved['model']
        self.scaler = saved['scaler']
        self.is_trained = True
```

### 3. Svelte Frontend: Correlation Dashboard

```svelte
<!-- frontend/src/routes/correlations.svelte -->
<script>
  import { onMount } from 'svelte';
  import CorrelationTable from '../components/CorrelationTable.svelte';
  
  // Main cryptocurrencies to analyze
  const mainCoins = [
    { id: 'BTC', name: 'Bitcoin', icon: 'ğŸŸ ' },
    { id: 'ETH', name: 'Ethereum', icon: 'ğŸ”·' },
    { id: 'XRP', name: 'Ripple', icon: 'âœ–ï¸' },
    { id: 'SOL', name: 'Solana', icon: 'ğŸŒ€' },
    { id: 'USDT', name: 'Tether', icon: 'ğŸ’µ' },
    { id: 'BNB', name: 'Binance Coin', icon: 'ğŸ…±ï¸' }
  ];

  let activeTab = 'BTC';
  let correlations = {};
  let loading = true;
  let lastUpdated = null;
  let socket;

  onMount(() => {
    // Initialize with data for Bitcoin
    fetchData(activeTab);
    setupWebSocket();
  });

  async function fetchData(coin) {
    loading = true;
    try {
      const response = await fetch(`/api/correlations/${coin}`);
      if (!response.ok) throw new Error('Failed to fetch data');
      
      const data = await response.json();
      correlations = {
        ...correlations,
        [coin]: data
      };
      
      lastUpdated = new Date();
    } catch (error) {
      console.error('Error fetching correlation data:', error);
    } finally {
      loading = false;
    }
  }

  function setupWebSocket() {
    // Setup WebSocket for real-time updates
    socket = new WebSocket(`ws://${location.host}/ws/correlations`);
    
    socket.onopen = () => {
      console.log('WebSocket connection established');
    };
    
    socket.onmessage = (event) => {
      const data = JSON.parse(event.data);
      if (data.type === 'correlation_update') {
        correlations = {
          ...correlations,
          [data.coin]: data.correlations
        };
        lastUpdated = new Date();
      }
    };
    
    socket.onclose = () => {
      console.log('WebSocket connection closed');
      // Reconnect after a delay
      setTimeout(setupWebSocket, 5000);
    };
  }

  function handleTabChange(coin) {
    activeTab = coin;
    if (!correlations[coin]) {
      fetchData(coin);
    }
  }
</script>

<div class="correlation-dashboard">
  <header>
    <h1>ğŸ“Š Cryptocurrency Correlation Dashboard</h1>
    <div class="last-updated">
      {#if lastUpdated}
        Last updated: {lastUpdated.toLocaleTimeString()}
      {:else}
        Fetching data...
      {/if}
    </div>
  </header>

  <div class="tabs">
    {#each mainCoins as coin}
      <button 
        class={activeTab === coin.id ? 'active' : ''}
        on:click={() => handleTabChange(coin.id)}
      >
        <span class="icon">{coin.icon}</span>
        <span class="name">{coin.name}</span>
      </button>
    {/each}
  </div>

  <div class="content">
    {#if loading}
      <div class="loading">
        <div class="spinner"></div>
        <p>Analyzing market correlations...</p>
      </div>
    {:else if correlations[activeTab]}
      <CorrelationTable 
        data={correlations[activeTab]} 
        mainCoin={activeTab}
      />
    {:else}
      <p>No correlation data available for {activeTab}</p>
    {/if}
  </div>
</div>

<style>
  .correlation-dashboard {
    max-width: 1200px;
    margin: 0 auto;
    padding: 2rem;
  }

  header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 2rem;
  }

  h1 {
    font-size: 1.8rem;
    font-weight: 600;
    color: #333;
  }

  .last-updated {
    font-size: 0.9rem;
    color: #666;
  }

  .tabs {
    display: flex;
    gap: 0.5rem;
    margin-bottom: 2rem;
    overflow-x: auto;
    padding-bottom: 0.5rem;
  }

  .tabs button {
    display: flex;
    align-items: center;
    gap: 0.5rem;
    padding: 0.75rem 1.25rem;
    border: none;
    border-radius: 8px;
    background: #f5f5f5;
    cursor: pointer;
    transition: background 0.2s;
  }

  .tabs button:hover {
    background: #e9e9e9;
  }

  .tabs button.active {
    background: #2563eb;
    color: white;
  }

  .icon {
    font-size: 1.25rem;
  }

  .content {
    background: white;
    border-radius: 12px;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    padding: 1.5rem;
  }

  .loading {
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    padding: 3rem;
  }

  .spinner {
    width: 40px;
    height: 40px;
    border: 4px solid #f3f3f3;
    border-top: 4px solid #2563eb;
    border-radius: 50%;
    animation: spin 1s linear infinite;
    margin-bottom: 1rem;
  }

  @keyframes spin {
    0% { transform: rotate(0deg); }
    100% { transform: rotate(360deg); }
  }
</style>
```

### 4. CorrelationTable Component

```svelte
<!-- frontend/src/components/CorrelationTable.svelte -->
<script>
  export let data;
  export let mainCoin;

  // Filter for currencies that outperform the main coin
  $: outperformers = data
    .filter(item => item.performance_delta > 0)
    .sort((a, b) => b.performance_delta - a.performance_delta);
</script>

<div class="correlation-table">
  <div class="header">
    <h2>Top 50 Correlated Currencies with {mainCoin}</h2>
    <div class="stats">
      <span class="positive">
        â–² {outperformers.length} outperforming
      </span>
      <span class="negative">
        â–¼ {data.length - outperformers.length} underperforming
      </span>
    </div>
  </div>

  <div class="table-container">
    <table>
      <thead>
        <tr>
          <th>#</th>
          <th>Symbol</th>
          <th>Correlation</th>
          <th>Performance Delta</th>
          <th>Current Price</th>
          <th>24h Volume</th>
          <th>Actions</th>
        </tr>
      </thead>
      <tbody>
        {#each outperformers as item, index}
          <tr>
            <td>{index + 1}</td>
            <td class="symbol-cell">
              <div class="symbol">{item.symbol}</div>
              <div class={item.performance_delta >= 0 ? 'change positive' : 'change negative'}>
                {item.performance_delta >= 0 ? 'â–²' : 'â–¼'} {Math.abs(item.performance_delta).toFixed(2)}%
              </div>
            </td>
            <td>
              <div class="correlation-bar">
                <div 
                  class="bar" 
                  style="width: {item.correlation_score * 100}%"
                ></div>
              </div>
              <div class="correlation-value">{item.correlation_score.toFixed(3)}</div>
            </td>
            <td>
              <div class="performance-bar">
                <div 
                  class="bar" 
                  style="width: {Math.min(Math.abs(item.performance_delta), 100)}%"
                ></div>
              </div>
              <div class="performance-value">+{item.performance_delta.toFixed(2)}%</div>
            </td>
            <td>${item.current_price.toFixed(item.current_price < 1 ? 8 : 2)}</td>
            <td>${(item.volume / 1000000).toFixed(2)}M</td>
            <td>
              <button class="trade-btn">Trade</button>
              <button class="analyze-btn">Analyze</button>
            </td>
          </tr>
        {/each}
      </tbody>
    </table>
  </div>
</div>

<style>
  .correlation-table {
    width: 100%;
  }

  .header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 1rem;
  }

  h2 {
    font-size: 1.4rem;
    font-weight: 600;
    color: #111;
  }

  .stats {
    display: flex;
    gap: 1rem;
  }

  .positive, .negative {
    padding: 0.25rem 0.75rem;
    border-radius: 999px;
    font-size: 0.875rem;
  }

  .positive {
    background-color: rgba(74, 222, 128, 0.1);
    color: #16a34a;
  }

  .negative {
    background-color: rgba(248, 113, 113, 0.1);
    color: #dc2626;
  }

  .table-container {
    overflow-x: auto;
  }

  table {
    width: 100%;
    border-collapse: collapse;
  }

  th, td {
    padding: 1rem;
    text-align: left;
    border-bottom: 1px solid #f1f1f1;
  }

  th {
    font-weight: 600;
    color: #555;
    background: #fafafa;
  }

  tr:hover {
    background: #f9fafb;
  }

  .symbol-cell {
    display: flex;
    flex-direction: column;
  }

  .symbol {
    font-weight: 600;
  }

  .change {
    font-size: 0.75rem;
    margin-top: 0.25rem;
  }

  .correlation-bar, .performance-bar {
    width: 100px;
    height: 6px;
    background: #eee;
    border-radius: 3px;
    overflow: hidden;
    margin-bottom: 0.25rem;
  }

  .correlation-bar .bar {
    height: 100%;
    background: #3b82f6;
  }

  .performance-bar .bar {
    height: 100%;
    background: #10b981;
  }

  .correlation-value, .performance-value {
    font-size: 0.75rem;
    color: #555;
  }

  .trade-btn, .analyze-btn {
    padding: 0.25rem 0.5rem;
    font-size: 0.75rem;
    border-radius: 4px;
    border: none;
    cursor: pointer;
    margin-right: 0.25rem;
  }

  .trade-btn {
    background: #2563eb;
    color: white;
  }

  .analyze-btn {
    background: #f3f4f6;
    color: #374151;
  }
</style>
```

### 5. Docker Compose Configuration

```yaml
# docker-compose.yml
version: '3.8'

services:
  # PostgreSQL Database
  db:
    image: postgres:14-alpine
    container_name: cryptobot-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-crypto_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-secretpassword}
      POSTGRES_DB: ${POSTGRES_DB:-crypto_bot}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data/pgdata
      - ./docker/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-crypto_user} -d ${POSTGRES_DB:-crypto_bot}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - cryptobot-network

  # Redis for Caching and Pub/Sub
  redis:
    image: redis:7-alpine
    container_name: cryptobot-redis
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD:-redispassword}
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - cryptobot-network

  # Elixir Backend
  backend:
    build:
      context: ./backend
      dockerfile: ../docker/Dockerfile.backend
    container_name: cryptobot-backend
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      DATABASE_URL: postgres://${POSTGRES_USER:-crypto_user}:${POSTGRES_PASSWORD:-secretpassword}@db:5432/${POSTGRES_DB:-crypto_bot}
      REDIS_URL: redis://:${REDIS_PASSWORD:-redispassword}@redis:6379
      SECRET_KEY_BASE: ${SECRET_KEY_BASE:-generatesecurekeyinproduction}
      API_KEY_ENCRYPTION_KEY: ${API_KEY_ENCRYPTION_KEY:-generatesecurekeyinproduction}
      ENVIRONMENT: ${ENVIRONMENT:-production}
      LOG_LEVEL: ${LOG_LEVEL:-info}
      SIMULATION_MODE: ${SIMULATION_MODE:-false}
      DEFAULT_RISK_PERCENTAGE: ${DEFAULT_RISK_PERCENTAGE:-1.0}
      MAX_CONCURRENT_TRADES: ${MAX_CONCURRENT_TRADES:-5}
      EMERGENCY_STOP_THRESHOLD: ${EMERGENCY_STOP_THRESHOLD:--7.5}
      ML_SERVICE_URL: http://ml_service:5000
      PORT: 4000
    ports:
      - "${BACKEND_PORT:-4000}:4000"
    volumes:
      - ./backend:/app
      - backend_build:/app/_build
      - backend_deps:/app/deps
    networks:
      - cryptobot-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Python ML Service
  ml_service:
    build:
      context: ./ml_service
      dockerfile: ../docker/Dockerfile.ml
      args:
        USE_GPU: ${USE_GPU:-false}
    container_name: cryptobot-ml
    restart: unless-stopped
    environment:
      REDIS_URL: redis://:${REDIS_PASSWORD:-redispassword}@redis:6379
      LOG_LEVEL: ${LOG_LEVEL:-info}
      USE_GPU: ${USE_GPU:-false}
      PYTHONUNBUFFERED: 1
    volumes:
      - ./ml_service:/app
      - ml_models:/app/models/saved
    networks:
      - cryptobot-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
      replicas: 1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Svelte Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: ../docker/Dockerfile.frontend
      args:
        VITE_API_URL: ${VITE_API_URL:-http://localhost:4000}
    container_name: cryptobot-frontend
    restart: unless-stopped
    depends_on:
      - backend
    ports:
      - "${FRONTEND_PORT:-3000}:80"
    networks:
      - cryptobot-network

  # Prometheus for Metrics
  prometheus:
    image: prom/prometheus:v2.41.0
    container_name: cryptobot-prometheus
    restart: unless-stopped
    volumes:
      - ./docker/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    networks:
      - cryptobot-network

  # Grafana for Dashboards
  grafana:
    image: grafana/grafana:9.4.3
    container_name: cryptobot-grafana
    restart: unless-stopped
    depends_on:
      - prometheus
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/provisioning:/etc/grafana/provisioning
      - ./docker/grafana/dashboards:/var/lib/grafana/dashboards
    ports:
      - "${GRAFANA_PORT:-3001}:3000"
    networks:
      - cryptobot-network

networks:
  cryptobot-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  backend_build:
  backend_deps:
  ml_models:
  prometheus_data:
  grafana_data:
```

### 6. Start Script

```bash
#!/bin/bash
# =========================================================================
# Crypto-Trading-Bot Startup Script
# =========================================================================
# This script initializes and starts all components of the
# self-learning crypto trading bot in the correct order.
# =========================================================================

# Colors for better readability
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration file
ENV_FILE=".env"
DOCKER_COMPOSE="docker-compose.yml"

# Display banner
echo -e "${BLUE}"
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘           ADAPTIVE CRYPTO-TRADING-BOT           â•‘"
echo "â•‘                                                  â•‘"
echo "â•‘        Self-Learning â€¢ AI-Powered â€¢ Secure       â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo -e "${NC}"

# Check if in correct directory
if [ ! -f "docker-compose.yml" ]; then
    echo -e "${RED}Error: docker-compose.yml not found.${NC}"
    echo -e "Please run this script from the project's root directory."
    exit 1
fi

# Check if .env exists
if [ ! -f $ENV_FILE ]; then
    echo -e "${YELLOW}Warning: .env file not found.${NC}"
    echo -e "Creating .env from .env.example..."
    
    if [ -f ".env.example" ]; then
        cp .env.example .env
        echo -e "${GREEN}.env file created.${NC}"
        echo -e "${YELLOW}IMPORTANT: Please edit the .env file with your configuration before continuing.${NC}"
        read -p "Continue without editing .env? (y/N): " CONTINUE
        if [[ ! "$CONTINUE" =~ ^[yY]$ ]]; then
            echo "Startup aborted. Please edit the .env file and restart."
            exit 0
        fi
    else
        echo -e "${RED}Error: .env.example not found.${NC}"
        echo "Please create an .env file manually."
        exit 1
    fi
fi

# Check Docker and Docker Compose
echo -e "${BLUE}Checking dependencies...${NC}"

if ! command -v docker &> /dev/null; then
    echo -e "${RED}Error: Docker is not installed.${NC}"
    echo "Please install Docker: https://docs.docker.com/get-docker/"
    exit 1
fi

if ! docker info &> /dev/null; then
    echo -e "${RED}Error: Docker daemon is not running or you don't have permissions.${NC}"
    echo "Please start the Docker daemon or add your user to the docker group."
    exit 1
fi

# Check Docker Compose (v1 and v2)
if ! command -v docker-compose &> /dev/null && ! docker compose version &> /dev/null; then
    echo -e "${RED}Error: Docker Compose is not installed.${NC}"
    echo "Please install Docker Compose: https://docs.docker.com/compose/install/"
    exit 1
fi

# Docker Compose command based on version
if command -v docker-compose &> /dev/null; then
    COMPOSE_CMD="docker-compose"
else
    COMPOSE_CMD="docker compose"
fi

# Validate configuration
echo -e "${BLUE}Validating configuration...${NC}"

# Check API keys
API_KEYS_MISSING=false
source $ENV_FILE

# Arrays for supported exchanges and required variables
EXCHANGES=("BINANCE" "COINBASE" "KRAKEN")
REQUIRED_VARS=("API_KEY" "API_SECRET")

# At least one exchange must be configured
CONFIGURED_EXCHANGES=0

for EXCHANGE in "${EXCHANGES[@]}"; do
    API_KEY_VAR="${EXCHANGE}_API_KEY"
    
    if [ -n "${!API_KEY_VAR}" ]; then
        CONFIGURED_EXCHANGES=$((CONFIGURED_EXCHANGES+1))
        echo -e "${GREEN}âœ“ ${EXCHANGE} API configuration found${NC}"
    fi
done

if [ $CONFIGURED_EXCHANGES -eq 0 ]; then
    echo -e "${RED}Error: No exchange API configured.${NC}"
    echo "Please add at least one API key set in the .env file."
    API_KEYS_MISSING=true
fi

# Check Simulation Mode
if [ "$SIMULATION_MODE" = "true" ]; then
    echo -e "${YELLOW}âš  Simulation mode is enabled. No real trades will be executed.${NC}"
fi

# If important configurations are missing, warn and get confirmation
if [ "$API_KEYS_MISSING" = true ]; then
    echo -e "${YELLOW}âš  Some important configurations are missing.${NC}"
    read -p "Continue anyway? (y/N): " CONTINUE
    if [[ ! "$CONTINUE" =~ ^[yY]$ ]]; then
        echo "Startup aborted. Please add the missing configurations."
        exit 0
    fi
fi

# Check directory structure
echo -e "${BLUE}Checking project structure...${NC}"
REQUIRED_DIRS=("backend" "ml_service" "frontend" "docker")
for DIR in "${REQUIRED_DIRS[@]}"; do
    if [ ! -d "$DIR" ]; then
        echo -e "${RED}Error: Directory '$DIR' not found.${NC}"
        echo "Please ensure you haven't modified the project structure."
        exit 1
    fi
done

# Try to stop old containers if any
echo -e "${BLUE}Cleaning up running containers...${NC}"
$COMPOSE_CMD down 2>/dev/null

# Check GPU support
if [ "$USE_GPU" = "true" ]; then
    echo -e "${BLUE}Checking GPU support...${NC}"
    
    if ! command -v nvidia-smi &> /dev/null; then
        echo -e "${YELLOW}Warning: NVIDIA drivers not found, but USE_GPU=true.${NC}"
        echo "GPU may not be properly attached."
    else
        # NVIDIA driver found, show info
        echo -e "${GREEN}NVIDIA GPU detected:${NC}"
        nvidia-smi --query-gpu=name,driver_version --format=csv,noheader
    fi
fi

# Ensure all needed directories exist
echo -e "${BLUE}Creating necessary directories...${NC}"
mkdir -p logs data/db data/ml_models

# Start containers
echo -e "${BLUE}Starting the Crypto Trading Bot...${NC}"
echo "This may take a few minutes, especially on first startup."

if [ "$DEBUG" = "true" ]; then
    # Start in debug mode without detached mode to see logs
    $COMPOSE_CMD up --build
else
    # Start in background
    $COMPOSE_CMD up -d --build
    
    # Wait for containers
    echo -e "${BLUE}Waiting for containers...${NC}"
    attempt=0
    max_attempts=30
    
    until $COMPOSE_CMD ps | grep -q "cryptobot-backend.*running" || [ $attempt -eq $max_attempts ]; do
        echo -n "."
        sleep 2
        attempt=$((attempt+1))
    done
    
    if [ $attempt -eq $max_attempts ]; then
        echo -e "\n${RED}Timeout waiting for containers.${NC}"
        echo "Please check logs with: $COMPOSE_CMD logs"
        exit 1
    fi
    
    echo -e "\n${GREEN}All containers started!${NC}"
    
    # Get port info
    BACKEND_PORT=${BACKEND_PORT:-4000}
    FRONTEND_PORT=${FRONTEND_PORT:-3000}
    
    # Show access information
    echo -e "${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "${GREEN}  Crypto Trading Bot successfully started!${NC}"
    echo -e "${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "Frontend: ${BLUE}http://localhost:$FRONTEND_PORT${NC}"
    echo -e "API:      ${BLUE}http://localhost:$BACKEND_PORT/api${NC}"
    echo -e "Logs:     ${BLUE}$COMPOSE_CMD logs -f${NC}"
    echo
    echo -e "${YELLOW}Note: First ML model initialization may take a few minutes.${NC}"
    echo -e "${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
fi

exit 0
```

## Security Considerations

### 1. API Key Management

The bot securely stores API keys using encryption. Never share your API keys or commit them to version control.

```elixir
# backend/lib/crypto_bot/exchanges/api_key_manager.ex
defmodule CryptoBot.Exchanges.APIKeyManager do
  @encryption_key System.get_env("API_KEY_ENCRYPTION_KEY")

  def encrypt_key(api_key) do
    # Implement AES encryption
    :crypto.crypto_one_time(
      :aes_256_gcm,
      decode_key(@encryption_key),
      :crypto.strong_rand_bytes(16),
      api_key,
      [],
      true
    )
  end

  def decrypt_key(encrypted_key) do
    # Implement AES decryption
    :crypto.crypto_one_time(
      :aes_256_gcm,
      decode_key(@encryption_key),
      # Extract IV from encrypted data
      binary_part(encrypted_key, 0, 16),
      binary_part(encrypted_key, 16, byte_size(encrypted_key) - 16),
      [],
      false
    )
  end

  defp decode_key(key_string) do
    Base.decode64!(key_string)
  end
end
```

### 2. Risk Management

The bot includes risk management features to protect your portfolio:

- **Maximum Position Size**: Limits the percentage of your portfolio in any single trade
- **Stop-Loss**: Automatic stop-loss orders to limit potential losses
- **Emergency Stop**: Trading automatically halts if portfolio drawdown exceeds threshold
- **Exchange Rate Limiting**: Respects exchange API rate limits to avoid IP bans

## Using the Bot

### 1. Dashboard Navigation

The main dashboard provides:

- **Portfolio Overview**: Current holdings, value, and performance
- **Active Strategies**: Currently running strategies and their performance
- **Market Analysis**: Current market regime detection and indicators
- **Correlation Dashboard**: Discover correlated cryptocurrencies for opportunities

### 2. Setting Up Trading

1. Configure exchange API keys in Settings
2. Set your risk tolerance and trading preferences
3. Select cryptocurrencies to monitor and trade
4. Choose automatic or manual trading mode
5. Monitor performance in real-time

### 3. Advanced Features

- **Backtesting**: Test strategies on historical data
- **Strategy Customization**: Adjust parameters for trading strategies
- **Alerts**: Set custom alerts for price movements or trading signals
- **Reports**: Generate performance reports and export data

## Contribution Guidelines

1. Fork the repository
2. Create a feature branch
3. Make changes following the established code style
4. Write tests for new functionality
5. Create a pull request

## License

This project is licensed under the MIT License. See the LICENSE file for details.
